{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B7Aae4eIApD"
      },
      "source": [
        "Creating the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4RLbL-KzE1y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import pickle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
        "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import roc_auc_score, classification_report, roc_curve, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "#from bayes_opt import BayesianOptimization\n",
        "pd.set_option('display.max_rows', None)\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "tf.compat.v1.random.set_random_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEVD9Q24-KY0"
      },
      "outputs": [],
      "source": [
        "SMOTE = SMOTE()\n",
        "# fold-accuracy plot\n",
        "def plot_acc(num_folds, acc_per_fold):\n",
        "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "    plt.style.use('ggplot')\n",
        "    folds = range(1, len(acc_per_fold) + 1)\n",
        "    plt.plot(folds, acc_per_fold, '-r^', label='Validation acc')\n",
        "    plt.xticks(np.arange(1, num_folds + 1, 1))\n",
        "    plt.title('Validation accuracy per fold')\n",
        "    plt.xlabel('Fold'), plt.ylabel('Accuracy'), plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "def earlystopping(min_delta, patience):\n",
        "  es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                    min_delta=min_delta,\n",
        "                                    patience=patience,\n",
        "                                    restore_best_weights=True)\n",
        "  return es_cb\n",
        "def generate_generalization_metrics(fold_no, model_name, model_scores):\n",
        "  print('=' * 50)\n",
        "  print(f'> Score for fold {fold_no}:\\n'\n",
        "        f'loss: {model_scores[0]:.2f}, '\n",
        "        f'accuracy: {model_scores[1]:.2f}\\n')\n",
        "  loss_per_fold.append(model_scores[0])\n",
        "  acc_per_fold.append(model_scores[1])\n",
        "\n",
        "  print('>>> Summmary of scores per fold: <<<')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "       print(f'Fold {i+1} - Loss: {loss_per_fold[i]:.2f}, Accuracy: {acc_per_fold[i]:.2f}')\n",
        "  print('Average scores for all folds:\\n'\n",
        "          f'Accuracy: {np.mean(acc_per_fold):.2f} (+- {np.std(acc_per_fold):.2f})\\n'\n",
        "          f'Loss: {np.mean(loss_per_fold):.2f}\\n'\n",
        "          f'{\"=\" * 50}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TFua0RBeuTM"
      },
      "outputs": [],
      "source": [
        "num_steps = 100\n",
        "def lstm_data_transform(x_data, y_data, num_steps= num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training\n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqmn1LSABO8d",
        "outputId": "13060470-c002-436f-b4d0-99eb87982732"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('combined1.csv')\n",
        "data['Subject'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJUelM8L9uKE",
        "outputId": "be7466ab-ad8d-4e34-f28a-e977101b98d9"
      },
      "outputs": [],
      "source": [
        "data['Subject'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization and correlation analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "eqRLFzUajpS3",
        "outputId": "f1fb2e5f-cace-4939-b9c7-f9ed82807612"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "corr = data[['X', 'Y', 'Z']].corr()\n",
        "sns.heatmap(corr, annot=True,\n",
        "    cmap='Blues',\n",
        "    vmin=-1.0, vmax=1.0,\n",
        "    square=True, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "MhRAx9IGnFvn",
        "outputId": "61e73f15-7099-4b49-b6a0-58e82ff8299d"
      },
      "outputs": [],
      "source": [
        "data[['X', 'Y', 'Z']].iloc[50000:50200].plot(figsize=(10, 5))\n",
        "\n",
        "#plt.legend(fontsize=\"large\")\n",
        "plt.xlabel(\"Time (1/60 S)\")\n",
        "plt.ylabel(\"Acceleration\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DJMvXuw_uM6"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "tf.compat.v1.random.set_random_seed(1234)\n",
        "dataset_train = data[data['Subject'].isin(['C16','C17','C19','C20','C21','C22','C23','C25','C31','C33',\n",
        "                                           'C34','C35','C36', 'C50','C57',\n",
        "                                           'P527','P436','P440','P445','P513','P507','P432','P441','P488','P433'\n",
        "                                           ,'P484','P483','P482','P528','P466','P487'\n",
        "                                           ])]\n",
        "dataset_valid = data[data['Subject'].isin(['C37','C39','C40','C41','P469','P462','P444','P460'])]\n",
        "dataset_test = data[data['Subject'].isin(['C11','C49','C53','C48','C38','C43','P459','P458','P457'\n",
        ",'P450','P473','P477'\n",
        ",'P503'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDg8hZWE_4p1",
        "outputId": "460dbfe1-1ad2-484f-bacd-794982c080ea"
      },
      "outputs": [],
      "source": [
        "print(dataset_train.Subject.unique())\n",
        "print(dataset_valid.Subject.unique())\n",
        "print(dataset_test.Subject.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGDYQ8yuL6I4",
        "outputId": "9708075f-648d-48bd-e560-f9d507ebf58e"
      },
      "outputs": [],
      "source": [
        "dataset_train.Subject.isin(dataset_test.Subject).unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN7CIU4Rjlug",
        "outputId": "4ddab478-1f87-448b-ddf7-079e625d95ce"
      },
      "outputs": [],
      "source": [
        "x_train1  = pd.DataFrame(dataset_train.iloc[:, [1,2]].values)\n",
        "y_train1 = pd.DataFrame(dataset_train.iloc[:, 3:4].values)\n",
        "\n",
        "x_valid1  = pd.DataFrame(dataset_valid.iloc[:, [1,2]].values)\n",
        "y_valid1 = pd.DataFrame(dataset_valid.iloc[:, 3:4].values)\n",
        "\n",
        "x_test1  = pd.DataFrame(dataset_test.iloc[:, [1,2]].values)\n",
        "y_test1 = pd.DataFrame(dataset_test.iloc[:, 3:4].values)\n",
        "print('x_train1.shape',x_train1.shape)\n",
        "print('x_valid1.shape',x_valid1.shape)\n",
        "print('x_test1.shape',x_test1.shape)\n",
        "print('y_train1.shape',y_train1.shape)\n",
        "print('y_valid1.shape',y_valid1.shape)\n",
        "print('y_test1.shape',y_test1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the final model using the hyperparameters obtained from tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "IYVU6SiTFbn1",
        "outputId": "f21a71a5-8710-464a-fa77-0129266e4c5d"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y_train1 = le.fit_transform(y_train1)\n",
        "y_valid1 = le.transform(y_valid1)\n",
        "y_test1 = le.transform(y_test1)\n",
        "\n",
        "scaler_x = StandardScaler()\n",
        "\n",
        "x_train1_sc = scaler_x.fit_transform(x_train1)\n",
        "x_valid1_sc = scaler_x.transform(x_valid1)\n",
        "x_test1_sc = scaler_x.transform(x_test1)\n",
        "\n",
        "# to keep constant notation\n",
        "y_train1_sc = y_train1\n",
        "y_valid1_sc = y_valid1\n",
        "y_test1_sc = y_test1\n",
        "\n",
        "\n",
        "x_train1_sc = np.array(x_train1_sc)\n",
        "x_valid1_sc = np.array(x_valid1_sc)\n",
        "x_test1_sc = np.array(x_test1_sc)\n",
        "\n",
        "y_train1_sc = np.array(y_train1_sc)\n",
        "y_valid1_sc = np.array(y_valid1_sc)\n",
        "y_test1_sc = np.array(y_test1_sc)\n",
        "\n",
        "num_steps = 100\n",
        "# training set\n",
        "(x_train1_transformed,\n",
        " y_train1_transformed) = lstm_data_transform(x_train1_sc, y_train1_sc, num_steps=num_steps)\n",
        "assert x_train1_transformed.shape[0] == y_train1_transformed.shape[0]\n",
        "# validation set\n",
        "(x_valid1_transformed,\n",
        " y_valid1_transformed) = lstm_data_transform(x_valid1_sc, y_valid1_sc, num_steps=num_steps)\n",
        "assert x_valid1_transformed.shape[0] == y_valid1_transformed.shape[0]\n",
        "# test set\n",
        "(x_test1_transformed,\n",
        " y_test1_transformed) = lstm_data_transform(x_test1_sc, y_test1_sc, num_steps=num_steps)\n",
        "assert x_test1_transformed.shape[0] == y_test1_transformed.shape[0]\n",
        "\n",
        "\n",
        "shuffler = np.random.permutation(len(x_train1_transformed))\n",
        "x_train1_transformed = x_train1_transformed[shuffler]\n",
        "y_train1_transformed = y_train1_transformed[shuffler]\n",
        "\n",
        "\n",
        "num_steps = 100\n",
        "num_features = 2\n",
        "max_epochs = 1\n",
        "patience = 7\n",
        "min_delta = 1e-5\n",
        "batch_size = 4\n",
        "Beta1 = 0.9\n",
        "Beta2 = 0.999\n",
        "Epsilon = 10^-8\n",
        "optimizer = 'adam'\n",
        "\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(LSTM(4, activation='tanh', input_shape=(num_steps, num_features), return_sequences=True))\n",
        "model_1.add(Dropout(0.2))\n",
        "#model_1.add(LSTM(units = 16, return_sequences = True))\n",
        "#model_1.add(Dropout(0.5))\n",
        "#model_1.add(LSTM(units = 16, return_sequences = True))\n",
        "#model_1.add(Dropout(0.5))\n",
        "model_1.add(LSTM(units = 4, return_sequences = False))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "# compile\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# train\n",
        "model_1_history = model_1.fit(x_train1_transformed, y_train1_transformed,\n",
        "                        epochs=max_epochs,\n",
        "                        validation_data=(x_valid1_transformed, y_valid1_transformed),\n",
        "                        callbacks=[earlystopping(min_delta, patience)],\n",
        "                        batch_size=batch_size)\n",
        "# evaluate\n",
        "model_1_scores = model_1.evaluate(x_test1_transformed, y_test1_transformed, verbose=0)\n",
        "\n",
        "# predict\n",
        "test_predict = model_1.predict(x_test1_transformed)\n",
        "y_pred = (test_predict > 0.5)\n",
        "\n",
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test1_transformed, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test1_transformed, y_pred)\n",
        "\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(y_test1_transformed, y_pred)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "model_1_acc = model_1_scores[1]\n",
        "print(model_1_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhUmzeaTb0_0"
      },
      "outputs": [],
      "source": [
        "s = pd.DataFrame(dataset_test['Subject']).iloc[100: , :].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JfVzAXeZ2V1",
        "outputId": "59f3d7bd-b293-4e24-f038-47926ad4d0b9"
      },
      "outputs": [],
      "source": [
        "final = pd.DataFrame(np.concatenate((y_pred.reshape(len(y_pred),1), y_test1_transformed.reshape(len(y_test1_transformed),1)),1))\n",
        "final = pd.concat([final, s], axis=1)\n",
        "final.columns = ['Prediction','Actual','Subject']\n",
        "final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GjW63pujbZb"
      },
      "outputs": [],
      "source": [
        "final = final.groupby('Subject', as_index=False).mean()\n",
        "final['Prediction'] = (final.Prediction > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "X6ghx1GnkjLD",
        "outputId": "9f2088de-05fb-42a5-afd9-a69109e75368"
      },
      "outputs": [],
      "source": [
        "final['Prediction'] = final['Prediction'].astype(int)\n",
        "final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "ywhEAjA-GzXQ",
        "outputId": "03e59144-9ec2-4a28-a363-02d40145e30a"
      },
      "outputs": [],
      "source": [
        "from keras.backend import repeat\n",
        "final = pd.DataFrame(np.concatenate((y_pred.reshape(len(y_pred),1), y_test1_transformed.reshape(len(y_test1_transformed),1)),1))\n",
        "final.columns = ['predict','test']\n",
        "nrow = 3600\n",
        "final['pred'] = final.groupby(final.index // nrow)['predict'].transform('mean')\n",
        "final['prediction_result'] = (final.pred > 0.5)\n",
        "final['prediction'] = final['prediction_result'].astype(int)\n",
        "final = final.iloc[::3600,[1,4]]\n",
        "yt = final.iloc[:,[0]]\n",
        "yp = final.iloc[:,[1]]\n",
        "cm1 = confusion_matrix(yt, yp)\n",
        "print(cm1)\n",
        "accuracy_score(yt, yp)\n",
        "\n",
        "df_cm1 = pd.DataFrame(cm1, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm1, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(yt, yp)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the model on ActiGraph Acceleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNpGDtjV419E"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('combined2.csv')\n",
        "\n",
        "dataset_test = data[data['Subject'].isin(['s1007','s1003','s2015','s2021','s2012','s2038','s2014'])]\n",
        "\n",
        "x_test1  = dataset_test.iloc[:, [0,2]].values\n",
        "y_test1 = dataset_test.iloc[:, 6:7].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul5erMd35WOe",
        "outputId": "2c6bddde-fdf0-4e68-d933-8146205646e6"
      },
      "outputs": [],
      "source": [
        "y_test1 = le.transform(y_test1)\n",
        "\n",
        "x_test1_sc = scaler_x.transform(x_test1)\n",
        "\n",
        "y_test1_sc = y_test1\n",
        "\n",
        "x_test1_sc = np.array(x_test1_sc)\n",
        "\n",
        "y_test1_sc = np.array(y_test1_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E15lFTsD5X_v"
      },
      "outputs": [],
      "source": [
        "(x_test1_transformed,\n",
        " y_test1_transformed) = lstm_data_transform(x_test1_sc, y_test1_sc, num_steps=num_steps)\n",
        "assert x_test1_transformed.shape[0] == y_test1_transformed.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAzeLxex5YQl",
        "outputId": "f5e74f83-3ded-45a2-f8e9-5f029f297650"
      },
      "outputs": [],
      "source": [
        "test_predict = model_1.predict(x_test1_transformed)\n",
        "y_pred = (test_predict > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "B_nPVO8r5jwG",
        "outputId": "716710f0-1e9a-40da-b6dc-0a30aaa3695d"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test1_transformed, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test1_transformed, y_pred)\n",
        "\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(y_test1_transformed, y_pred)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpCYw4pxENIE"
      },
      "outputs": [],
      "source": [
        "final = pd.DataFrame(np.concatenate((y_pred.reshape(len(y_pred),1), y_test1_transformed.reshape(len(y_test1_transformed),1)),1))\n",
        "final.columns = ['Predict','Actual']\n",
        "\n",
        "final = final.reset_index()\n",
        "\n",
        "sub = pd.DataFrame(dataset_test.iloc[100:,5:]).reset_index()\n",
        "\n",
        "final1 = pd.concat([final, sub], axis=1)\n",
        "\n",
        "final1['pred'] = final1.groupby('Subject')['Predict'].transform('mean')\n",
        "final1['prediction_result'] = (final1.pred > 0.5)\n",
        "final1['Prediction'] = final1['prediction_result'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH5KEB4GEX3V"
      },
      "outputs": [],
      "source": [
        "final1 = final1[['Subject', 'Prediction', 'Actual']]\n",
        "final1 = final1.groupby(['Subject'], as_index = False).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "Db9Z6YF7EX_j",
        "outputId": "869da232-ffe6-42f9-c29f-242bdf19036f"
      },
      "outputs": [],
      "source": [
        "yt = final1['Actual']\n",
        "yp = final1['Prediction']\n",
        "cm1 = confusion_matrix(yt, yp)\n",
        "print(cm1)\n",
        "accuracy_score(yt, yp)\n",
        "\n",
        "df_cm1 = pd.DataFrame(cm1, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm1, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(yt, yp)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ltHKtNGQxu",
        "outputId": "c0840f1b-0564-4b41-864d-71100cd71894"
      },
      "outputs": [],
      "source": [
        "print(classification_report(yt, yp))\n",
        "print(\"Precision:{}\".format(precision_score(yp,yt)))\n",
        "print(\"Recall:{}\".format(recall_score(yp,yt)))\n",
        "print(\"F1 Score:{}\".format((f1_score(yp,yt))))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
