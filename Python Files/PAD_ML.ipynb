{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFiO8S5dvvSa"
      },
      "outputs": [],
      "source": [
        "#%pip install shap\n",
        "#%pip install featurewiz\n",
        "#import shap\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "#import featurewiz as FW\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, space_eval\n",
        "from sklearn.metrics import roc_auc_score, classification_report, roc_curve, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "#from bayes_opt import BayesianOptimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh5R13ZlOuQJ",
        "outputId": "ba145d56-1884-4b13-8e4d-96a813dc7a1e"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "data['Subject'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM2QZ1AylbHP"
      },
      "outputs": [],
      "source": [
        "g = data.groupby('PAD').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu1zuP--rNm-"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-3soywCXyj6L",
        "outputId": "0b9b1cfd-24d4-418d-e5c5-02ceefc76535"
      },
      "outputs": [],
      "source": [
        "def label (row):\n",
        "  if row['PAD'] == 0:\n",
        "    return \"Healthy\"\n",
        "  if row['PAD'] == 1:\n",
        "    return \"PAD\"\n",
        "\n",
        "data['Condition'] = data.apply(lambda row: label(row), axis=1)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMCMhDsRVwWD"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={'StepTime': 'StepTime', 'StanceTime': 'StanceTime', 'StrideTime': 'StrideTime', 'SwingTime': 'SwingTime',\n",
        "                     'StepTimeVrl': 'StepTime SV', 'StepTimeV': 'StepTime MV', 'StepTimeA': 'StepTime SA',\n",
        "                     'StanceTimeVrl': 'StanceTime SV', 'StanceTimeV': 'StanceTime MV', 'StanceTimeA': 'StanceTime SA',\n",
        "                     'StrideTimeVrl': 'StrideTime SV', 'StrideTimeV': 'StrideTime MV', 'StrideTimeA': 'StrideTime SA',\n",
        "                     'SwingTimeVrl': 'SwingTime SV', 'SwingTimeV': 'SwingTime MV', 'SwingTimeA': 'SwingTime SA',}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL-mFFs5v7p0"
      },
      "outputs": [],
      "source": [
        "d1 = data[['StepTime', 'StanceTime',\t'StrideTime',\t'SwingTime', 'Condition']]\n",
        "d1 = pd.melt(d1, id_vars='Condition', value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "_NUkHRGQrQzk",
        "outputId": "2dab84ad-3adb-4b26-b30d-1c57e18499ce"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(1, sharex=False, sharey=False, gridspec_kw={'hspace': 0}, figsize=(15, 5))\n",
        "bill = sns.load_dataset(\"tips\")\n",
        "sns.boxplot(x=\"variable\", y=\"value\", hue=\"Condition\", data=d1, palette=\"Dark2\", showfliers = False)\n",
        "ax.set(xlabel='Gait Characteristic', ylabel='Time (1 / 60 S)')\n",
        "[ax.axvline(x, color = 'black', linestyle='--') for x in [.5,1.5,2.5]]\n",
        "ax.tick_params(axis='x', rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8njcB4j3fr4"
      },
      "outputs": [],
      "source": [
        "d2 = data.drop(['StepTime', 'StanceTime',\t'StrideTime',\t'SwingTime', 'StrideTime SA' , 'PAD'], axis=1)\n",
        "d2 = pd.melt(d2, id_vars='Condition', value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "SLnalnLt38nT",
        "outputId": "33ef31d1-c419-4a3e-9c95-15a9c86a2202"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, sharex=False, sharey=False, gridspec_kw={'hspace': 0}, figsize=(15, 5))\n",
        "bill = sns.load_dataset(\"tips\")\n",
        "sns.boxplot(x=\"variable\", y=\"value\", hue=\"Condition\", data=d2, palette=\"Dark2\", showfliers = False)\n",
        "ax.set(xlabel='Gait Characteristic', ylabel='Value')\n",
        "[ax.axvline(x, color = 'black', linestyle='--') for x in [.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5]]\n",
        "ax.tick_params(axis='x', rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHBbfP45JeHk"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xioTrqwlzsaj"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "data.rename(columns={'StepTime': 'StepTime', 'StanceTime': 'StanceTime', 'StrideTime': 'StrideTime', 'SwingTime': 'SwingTime',\n",
        "                     'StepTimeVrl': 'StepTime SV', 'StepTimeV': 'StepTime MV', 'StepTimeA': 'StepTime SA',\n",
        "                     'StanceTimeVrl': 'StanceTime SV', 'StanceTimeV': 'StanceTime MV', 'StanceTimeA': 'StanceTime SA',\n",
        "                     'StrideTimeVrl': 'StrideTime SV', 'StrideTimeV': 'StrideTime MV', 'StrideTimeA': 'StrideTime SA',\n",
        "                     'SwingTimeVrl': 'SwingTime SV', 'SwingTimeV': 'SwingTime MV', 'SwingTimeA': 'SwingTime SA',}, inplace=True)\n",
        "dataset_train = data[data['Subject'].isin(['C16','C17','C19','C20','C21','C22','C23','C25','C31','C33','C34','C35','C36',\n",
        "                                           'C37','C39','C40','C41', 'C50', 'C57'\n",
        "                                           'P445','P527','P436','P440','P513','P507','P432','P441','P488','P433','P466'\n",
        "                                           ,'P484','P483','P482','P469','P462','P444','P460','P487','P528'\n",
        "                                           ])]\n",
        "\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEMWmndIIHRn",
        "outputId": "fade9795-18a2-4a93-fa98-9ae68ae15694"
      },
      "outputs": [],
      "source": [
        "dataset_train.Subject.isin(dataset_test.Subject).unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkGk6o_T6ON1",
        "outputId": "75ea93f3-1f07-4328-b63a-ba805ee12d5f"
      },
      "outputs": [],
      "source": [
        "dataset_train['Subject'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e9RKwI7N_ie"
      },
      "outputs": [],
      "source": [
        " dataset_train = dataset_train.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))\n",
        " dataset_test = dataset_test.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        " dataset_train = shuffle(dataset_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4xhAi1OcSzo",
        "outputId": "3c77a2d5-0c63-4c3b-eb1b-2b808e247e84"
      },
      "outputs": [],
      "source": [
        "dataset_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rhHQxkff1TW",
        "outputId": "26d9194e-6f08-46e7-d164-f44bbb156334"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "numeric_cols = [col for col in dataset_train.columns if is_numeric_dtype(dataset_train[col])]\n",
        "df_numeric = dataset_train[numeric_cols]\n",
        "df_numeric = df_numeric.drop(['PAD','StrideTime SV', 'StrideTime', 'SwingTime MV', 'StanceTime SA', 'StanceTime SV', 'StepTime', 'SwingTime SV', 'StepTime MV', 'StepTime SV', 'StanceTime', 'StrideTime MV'],1)\n",
        "# Calculate the VIF for each independent variable\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(df_numeric.values, i) for i in range(df_numeric.shape[1])]\n",
        "vif[\"features\"] = df_numeric.columns\n",
        "vif_sorted = vif.sort_values(by='VIF Factor', ascending=False)\n",
        "\n",
        "# Print the VIF values for each independent variable\n",
        "print(vif_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "RGOc3iRfWUIi",
        "outputId": "80361d6d-95b7-4e85-a001-0af59e6f9fd3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Load your dataset into a pandas dataframe\n",
        "X = dataset_train[['PAD']]\n",
        "# Scale the input variables\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Calculate the VIF for each independent variable\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(X_scaled, i) for i in range(X.shape[1])]\n",
        "vif[\"features\"] = X.columns\n",
        "\n",
        "# Print the VIF values for each independent variable\n",
        "print(vif)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNtDWFgT0J8U",
        "outputId": "13f80abc-b2ed-4e97-e6d2-be73abfaa966"
      },
      "outputs": [],
      "source": [
        "#X = dataset_train.drop(['PAD'], 1)\n",
        "#y = dataset_train['PAD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ILUOXiJbqmrZ",
        "outputId": "caa6a296-7058-41b4-b3f9-e897f36f6eee"
      },
      "outputs": [],
      "source": [
        "FW.featurewiz(dataname=dataset_train, target='PAD',feature_egg = 'interaction', corr_limit=0.90, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNm2Dbv61M8"
      },
      "outputs": [],
      "source": [
        "X_train = dataset_train[['StepTime', 'StanceTime', 'StrideTime', 'SwingTime',\n",
        "       'StepTime SV', 'StepTime MV', 'StepTime SA', 'StanceTime SV', 'StanceTime MV',\n",
        "       'StanceTime SA', 'StrideTime SV', 'StrideTime MV', 'StrideTime SA',\n",
        "       'SwingTime SV', 'SwingTime MV', 'SwingTime SA']]\n",
        "y_train = dataset_train[['PAD']]\n",
        "\n",
        "X_test = dataset_test[['StepTime', 'StanceTime', 'StrideTime', 'SwingTime',\n",
        "       'StepTime SV', 'StepTime MV', 'StepTime SA', 'StanceTime SV', 'StanceTime MV',\n",
        "       'StanceTime SA', 'StrideTime SV', 'StrideTime MV', 'StrideTime SA',\n",
        "       'SwingTime SV', 'SwingTime MV', 'SwingTime SA']]\n",
        "y_test = dataset_test[['PAD']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJHVIZL_G25J"
      },
      "source": [
        "### Logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4Ud541aNDtf",
        "outputId": "d9926ce0-34a3-4659-e8b6-51e83b4cd2d6"
      },
      "outputs": [],
      "source": [
        "logit_model = sm.Logit(y_train, X_train)\n",
        "result = logit_model.fit()\n",
        "print(result.summary2())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0YqF1S7R6CM",
        "outputId": "4681dfc5-5c0c-41e1-ea8d-4f0af4c4119d"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjoEdd0SFb2S"
      },
      "outputs": [],
      "source": [
        "# Dropping first 4:\n",
        "X_train = dataset_train[[\n",
        "       'StepTimeVrl', 'StepTimeV', 'StepTimeA', 'StanceTimeVrl', 'StanceTimeV',\n",
        "       'StanceTimeA', 'StrideTimeVrl', 'StrideTimeV', 'StrideTimeA',\n",
        "       'SwingTimeVrl', 'SwingTimeV', 'SwingTimeA']]\n",
        "\n",
        "X_test = dataset_test[[\n",
        "       'StepTimeVrl', 'StepTimeV', 'StepTimeA', 'StanceTimeVrl', 'StanceTimeV',\n",
        "       'StanceTimeA', 'StrideTimeVrl', 'StrideTimeV', 'StrideTimeA',\n",
        "       'SwingTimeVrl', 'SwingTimeV', 'SwingTimeA']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "AjtqdNPUHaPH",
        "outputId": "c125a396-6932-4c8f-af0b-91202f841dde"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Precision:{}\".format(precision_score(y_pred,y_test)))\n",
        "print(\"Recall:{}\".format(recall_score(y_pred,y_test)))\n",
        "print(\"F1 Score:{}\".format((f1_score(y_pred,y_test))))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, y_pred)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "sYWD6gsB1tN6",
        "outputId": "9ccff283-9038-41a4-d928-4bcfc2bf9b28"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]\n",
        "sub = pd.DataFrame(dataset_test['Subject'])\n",
        "sub['actual'] = y_test\n",
        "sub['prediction'] = y_pred\n",
        "f = sub.groupby(\"Subject\", as_index = False).mean()\n",
        "\n",
        "print(classification_report(f.actual, f.prediction))\n",
        "print(\"Precision:{}\".format(precision_score(f.prediction,f.actual)))\n",
        "print(\"Recall:{}\".format(recall_score(f.prediction,f.actual)))\n",
        "print(\"F1 Score:{}\".format((f1_score(f.prediction,f.actual))))\n",
        "\n",
        "cm = confusion_matrix(f.actual, f.prediction)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(f.actual, f.prediction)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "pIB1nTbzgyTm",
        "outputId": "681cd1ee-7b68-4e70-8290-c740fe984465"
      },
      "outputs": [],
      "source": [
        "f = f[['Subject', 'prediction', 'actual']]\n",
        "f.columns = ['Subject', 'Prediction', 'Actual']\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "GL2yOS_bJ3S3",
        "outputId": "af5e7e58-8906-42fc-cc27-1f9c93616188"
      },
      "outputs": [],
      "source": [
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSdpe0HN5vlr"
      },
      "source": [
        "Final edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI-FNPVghyfG"
      },
      "outputs": [],
      "source": [
        "# Applying VIF test\n",
        "X_train = dataset_train[['StepTime SA', 'SwingTime SA', 'SwingTime', 'StrideTime SA', 'StanceTime MV']]\n",
        "X_test = dataset_test[['StepTime SA', 'SwingTime SA', 'SwingTime', 'StrideTime SA', 'StanceTime MV']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tjLdoUxQYqY"
      },
      "outputs": [],
      "source": [
        "X_train = dataset_train[['StanceTime SV', 'SwingTime SV', 'StrideTime SV', 'StepTime MV', 'StepTime SA', 'SwingTime SA',\n",
        "                         'StanceTime SA', 'StrideTime SA']]\n",
        "\n",
        "X_test = dataset_test[['StanceTime SV', 'SwingTime SV', 'StrideTime SV', 'StepTime MV', 'StepTime SA', 'SwingTime SA',\n",
        "                         'StanceTime SA', 'StrideTime SA']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2qShy0l5uFk",
        "outputId": "7ea59763-eac1-43c5-a738-5896d4f5df77"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assume X_train, y_train, X_test, and y_test are your training and test data\n",
        "logistic_regression = LogisticRegression()\n",
        "accuracy_scores = cross_val_score(logistic_regression, X_train, y_train, cv=5)\n",
        "\n",
        "print(f\"Cross-validation accuracy: {accuracy_scores.mean():.2f} +/- {accuracy_scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpxMAUlSARe-",
        "outputId": "3a0d67c7-d847-4fb9-da99-eb6c7d851231"
      },
      "outputs": [],
      "source": [
        "logistic_regression.fit(X_train, y_train)\n",
        "y_pred = logistic_regression.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test set accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "Tp8o7UiCAWzB",
        "outputId": "7e9c074f-f12c-4d0d-9e31-2b645a79e8ff"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]\n",
        "sub = pd.DataFrame(dataset_test['Subject'])\n",
        "sub['actual'] = y_test\n",
        "sub['prediction'] = y_pred\n",
        "f = sub.groupby(\"Subject\", as_index = False).mean()\n",
        "f['prediction'] = np.round(f['prediction'])\n",
        "\n",
        "print(classification_report(f.actual, f.prediction))\n",
        "print(\"Precision:{}\".format(precision_score(f.prediction,f.actual)))\n",
        "print(\"Recall:{}\".format(recall_score(f.prediction,f.actual)))\n",
        "print(\"F1 Score:{}\".format((f1_score(f.prediction,f.actual))))\n",
        "\n",
        "cm = confusion_matrix(f.actual, f.prediction)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(f.actual, f.prediction)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ7lfNSUDfsv",
        "outputId": "e76e7bc1-dda3-488d-b9da-839411757051"
      },
      "outputs": [],
      "source": [
        "# Assume logistic_regression is your fitted logistic regression model\n",
        "feature_names = ['StepTime', 'StanceTime', 'StrideTime', 'SwingTime', 'StepTimeVrl',\n",
        "       'StepTimeV', 'StepTimeA', 'StanceTimeVrl', 'StanceTimeV', 'StanceTimeA',\n",
        "       'StrideTimeVrl', 'StrideTimeV', 'StrideTimeA', 'SwingTimeVrl',\n",
        "       'SwingTimeV', 'SwingTimeA']\n",
        "coef_abs = np.abs(logistic_regression.coef_[0])\n",
        "sorted_idx = np.argsort(coef_abs)[::-1]\n",
        "\n",
        "# Print the feature names and corresponding coefficients in descending order of importance\n",
        "for i in sorted_idx:\n",
        "    print(f\"{feature_names[i]}: {logistic_regression.coef_[0][i]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTEvn4ryHBXf"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0MT7KUwoMks"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "data.rename(columns={'StepTime': 'StepTime', 'StanceTime': 'StanceTime', 'StrideTime': 'StrideTime', 'SwingTime': 'SwingTime',\n",
        "                     'StepTimeVrl': 'StepTime SV', 'StepTimeV': 'StepTime MV', 'StepTimeA': 'StepTime SA',\n",
        "                     'StanceTimeVrl': 'StanceTime SV', 'StanceTimeV': 'StanceTime MV', 'StanceTimeA': 'StanceTime SA',\n",
        "                     'StrideTimeVrl': 'StrideTime SV', 'StrideTimeV': 'StrideTime MV', 'StrideTimeA': 'StrideTime SA',\n",
        "                     'SwingTimeVrl': 'SwingTime SV', 'SwingTimeV': 'SwingTime MV', 'SwingTimeA': 'SwingTime SA',}, inplace=True)\n",
        "dataset_train = data[data['Subject'].isin(['C16','C17','C19','C20','C21','C22','C23','C25','C31','C33','C34','C35','C36',\n",
        "                                           'C37','C39','C40','C41', 'C50', 'C57'\n",
        "                                           'P445','P527','P436','P440','P513','P507','P432','P441','P488','P433','P466'\n",
        "                                           ,'P484','P483','P482','P469','P462','P444','P460','P487','P528'\n",
        "                                           ])]\n",
        "\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2xypERModEE"
      },
      "outputs": [],
      "source": [
        " dataset_train = dataset_train.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))\n",
        " dataset_test = dataset_test.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        " dataset_train = shuffle(dataset_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_cRwVSo1LVf",
        "outputId": "54eedd7e-503e-4cdc-9fa9-803f889a2197"
      },
      "outputs": [],
      "source": [
        "X = dataset_train.drop(['PAD'],1)\n",
        "Xt = dataset_test.drop(['PAD'],1)\n",
        "y_train = dataset_train[['PAD']]\n",
        "y_test = dataset_test[['PAD']]\n",
        "y = y_train.copy()\n",
        "yt = y_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md1dLvXLoD9s"
      },
      "outputs": [],
      "source": [
        "X = dataset_train[['SwingTime SA', 'SwingTime MV', 'StrideTime MV', 'StepTime SA']]\n",
        "\n",
        "Xt = dataset_test[['SwingTime SA', 'SwingTime MV', 'StrideTime MV', 'StepTime SA']]\n",
        "\n",
        "y_train = dataset_train[['PAD']]\n",
        "y_test = dataset_test[['PAD']]\n",
        "y = y_train.copy()\n",
        "yt = y_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zcKNoxupSsg",
        "outputId": "83831c1a-d8fd-4226-de2d-9b88fa2d9080"
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, tpe, hp\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def hyperopt_train_test(params):\n",
        "    clf = RandomForestClassifier(**params)\n",
        "    return cross_val_score(clf, X, y).mean()\n",
        "\n",
        "def f(params):\n",
        "    acc = hyperopt_train_test(params)\n",
        "    return {'loss': -acc, 'status': 'ok'}\n",
        "\n",
        "space = {\n",
        "    'max_depth': hp.choice('max_depth', range(1, 20)),\n",
        "    'max_features': hp.choice('max_features', range(1, len(X.columns))),\n",
        "    'n_estimators': 70, #hp.choice('n_estimators', range(0, 100)),\n",
        "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
        "    'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
        "    'min_samples_split' : hp.uniform ('min_samples_split', 0, 1)\n",
        "}\n",
        "\n",
        "best = fmin(f, space, algo=tpe.suggest, max_evals=100)\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGC4F0S3sneG",
        "outputId": "8d3a9d49-8008-4386-e835-3c4abdcdcd48"
      },
      "outputs": [],
      "source": [
        "best_params = space_eval(space, best)\n",
        "clf = RandomForestClassifier(**best_params)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Evaluate the classifier on the test set\n",
        "y_pred = clf.predict(Xt)\n",
        "accuracy = accuracy_score(yt, y_pred)\n",
        "print(f'Test accuracy: {accuracy:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "oPqu4VscFjZZ",
        "outputId": "e5b4d55a-2b79-4b39-a5ed-f9d51aea68be"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]\n",
        "sub = pd.DataFrame(dataset_test['Subject'])\n",
        "sub['actual'] = y_test\n",
        "sub['prediction'] = y_pred\n",
        "f = sub.groupby(\"Subject\", as_index = False).mean()\n",
        "\n",
        "print(classification_report(f.actual, f.prediction))\n",
        "print(\"Precision:{}\".format(precision_score(f.prediction,f.actual)))\n",
        "print(\"Recall:{}\".format(recall_score(f.prediction,f.actual)))\n",
        "print(\"F1 Score:{}\".format((f1_score(f.prediction,f.actual))))\n",
        "\n",
        "cm = confusion_matrix(f.actual, f.prediction)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(f.actual, f.prediction)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "psKDPYkr2XlH",
        "outputId": "d17a03a4-a32b-4b3a-c1d5-d1bcbf4c1264"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# Create an explainer object\n",
        "#explainer = shap.Explainer(clf, X)\n",
        "\n",
        "# Generate SHAP values for the test set\n",
        "#shap_values = explainer(Xt)\n",
        "\n",
        "shap_values = shap.TreeExplainer(clf).shap_values(X)\n",
        "\n",
        "# Plot the SHAP summary plot\n",
        "shap.summary_plot(shap_values, Xt, plot_type='bar', feature_names=Xt.columns, show=False)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6yVOKxPG9VB"
      },
      "outputs": [],
      "source": [
        "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
        "        'max_depth': hp.choice('max_depth', range(0,20)),\n",
        "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
        "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
        "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
        "        'n_estimators' : hp.choice('n_estimators', range(0,20))\n",
        "    }\n",
        "\n",
        "def objective(space):\n",
        "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
        "                                 max_features = space['max_features'],\n",
        "                                 min_samples_leaf = space['min_samples_leaf'],\n",
        "                                 min_samples_split = space['min_samples_split'],\n",
        "                                 n_estimators = space['n_estimators'],\n",
        "                                 )\n",
        "\n",
        "    accuracy = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
        "\n",
        "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "efXuS5TJQ039",
        "outputId": "3c6a7382-6858-4757-800f-dbf3ea9f3eb5"
      },
      "outputs": [],
      "source": [
        "trials = Trials()\n",
        "best = fmin(fn= objective,\n",
        "            space= space,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 5,\n",
        "            trials= trials)\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qk2me2H9e4W"
      },
      "outputs": [],
      "source": [
        "X_train = dataset_train[['SwingTimeVrl', 'SwingTimeV', 'StrideTimeVrl', 'StepTimeA']]\n",
        "\n",
        "X_test = dataset_test[['SwingTimeVrl', 'SwingTimeV', 'StrideTimeVrl', 'StepTimeA']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "xoZv5r_0ZPph",
        "outputId": "af51650a-ff51-4fa4-e796-e055a47f58cc"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(criterion = 'gini',\n",
        "                                       max_depth = best['max_depth'],\n",
        "                                       max_features = None,\n",
        "                                       min_samples_leaf = best['min_samples_leaf'],\n",
        "                                       min_samples_split = best['min_samples_split'],\n",
        "                                       n_estimators = best['n_estimators']\n",
        "                                       )\n",
        "trainedforest = model.fit(X_train, y_train)\n",
        "y_pred = trainedforest.predict(X_test)\n",
        "#print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kDZyuY6F5PB"
      },
      "outputs": [],
      "source": [
        "with open('RF_model.pickle', 'wb') as handle:\n",
        "    pickle.dump(trainedforest, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAGGsFpei76v",
        "outputId": "b41050c2-1adb-46ce-f0fd-1add81077938"
      },
      "outputs": [],
      "source": [
        "with open('RF_model.pickle', 'rb') as f:\n",
        "    trainedforest = pickle.load(f)\n",
        "\n",
        "y_pred = trainedforest.predict(X_test)\n",
        "#print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "wfD2WUhRpdEY",
        "outputId": "8cb9689e-42d3-4bfe-a431-6b7f93875b76"
      },
      "outputs": [],
      "source": [
        "shap_values = shap.TreeExplainer(model).shap_values(X_train)\n",
        "shap.summary_plot(shap_values, X_train, feature_names=X_train.columns, plot_type='bar')\n",
        "\n",
        "# FW: 'StanceTimeV','StepTimeA','StanceTimeA','StepTimeV','StrideTimeA','StrideTime'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "RIQzTDFpBE-F",
        "outputId": "d0986f5e-1bf6-4cfb-d698-e48ebdc24daa"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]\n",
        "sub = pd.DataFrame(dataset_test['Subject'])\n",
        "sub['actual'] = y_test\n",
        "sub['prediction'] = y_pred\n",
        "f = sub.groupby(\"Subject\", as_index = False).mean()\n",
        "\n",
        "print(classification_report(f.actual, f.prediction))\n",
        "print(\"Precision:{}\".format(precision_score(f.prediction,f.actual)))\n",
        "print(\"Recall:{}\".format(recall_score(f.prediction,f.actual)))\n",
        "print(\"F1 Score:{}\".format((f1_score(f.prediction,f.actual))))\n",
        "\n",
        "cm = confusion_matrix(f.actual, f.prediction)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(f.actual, f.prediction)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "C6qemTPenH6Q",
        "outputId": "4f3caccf-f0d8-43f3-8d6f-158d4e6c704a"
      },
      "outputs": [],
      "source": [
        "f = f[['Subject', 'prediction', 'actual']]\n",
        "f.columns = ['Subject', 'Prediction', 'Actual']\n",
        "f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNA0lq44IsAw"
      },
      "source": [
        "### SVM\n",
        "Drop 4 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iztNOn91I0Pd"
      },
      "outputs": [],
      "source": [
        "space = {\n",
        "      'C': hp.choice('C', np.arange(1,100,1)),\n",
        "      'kernel': hp.choice('kernel',['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "      'degree':hp.choice('degree',[1,2,3,4,5]),\n",
        "      'probability':hp.choice('probability',[True])\n",
        "      }\n",
        "\n",
        "\n",
        "def objective(space):\n",
        "    model = SVC(**space)\n",
        "    accuracy = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COuIltWozDlt",
        "outputId": "9f09b9e0-2f05-4fc0-da22-14297b1b5cbb"
      },
      "outputs": [],
      "source": [
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space = space,\n",
        "            algo = tpe.suggest,\n",
        "            max_evals = 30,\n",
        "            trials = trials)\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKICKvA_BLrX",
        "outputId": "c2a1e590-4031-4e9a-e79d-979cc005dfe5"
      },
      "outputs": [],
      "source": [
        "model = SVC(C = 35, #np.arange(0,100,1)[best['C']],\n",
        "            kernel = 'rbf',\n",
        "            degree = 1,\n",
        "            probability = 0\n",
        "            )\n",
        "\n",
        "trainedsvc = model.fit(X_train, y_train)\n",
        "y_pred = trainedsvc.predict(X_test)\n",
        "#print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "zNUBS5L-OVJl",
        "outputId": "129b308a-dbc6-40c9-f9d9-d577cf205f0e"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]\n",
        "sub = pd.DataFrame(dataset_test['Subject'])\n",
        "sub['actual'] = y_test\n",
        "sub['prediction'] = y_pred\n",
        "f = sub.groupby(\"Subject\", as_index = False).mean()\n",
        "\n",
        "print(classification_report(f.actual, f.prediction))\n",
        "print(\"Precision:{}\".format(precision_score(f.prediction,f.actual)))\n",
        "print(\"Recall:{}\".format(recall_score(f.prediction,f.actual)))\n",
        "print(\"F1 Score:{}\".format((f1_score(f.prediction,f.actual))))\n",
        "\n",
        "cm = confusion_matrix(f.actual, f.prediction)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(f.actual, f.prediction)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sqJ2u2zuA8U"
      },
      "outputs": [],
      "source": [
        "f = f[['Subject', 'prediction', 'actual']]\n",
        "f.columns = ['Subject', 'Prediction', 'Actual']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "pLmc9dvbvmjR",
        "outputId": "ce4f39b7-2bcf-44ed-935b-345aa2cbfe46"
      },
      "outputs": [],
      "source": [
        "f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emDLk5bZ4puz"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWnZdv-vUEYM"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "data.rename(columns={'StepTime': 'StepTime', 'StanceTime': 'StanceTime', 'StrideTime': 'StrideTime', 'SwingTime': 'SwingTime',\n",
        "                     'StepTimeVrl': 'StepTime SV', 'StepTimeV': 'StepTime MV', 'StepTimeA': 'StepTime SA',\n",
        "                     'StanceTimeVrl': 'StanceTime SV', 'StanceTimeV': 'StanceTime MV', 'StanceTimeA': 'StanceTime SA',\n",
        "                     'StrideTimeVrl': 'StrideTime SV', 'StrideTimeV': 'StrideTime MV', 'StrideTimeA': 'StrideTime SA',\n",
        "                     'SwingTimeVrl': 'SwingTime SV', 'SwingTimeV': 'SwingTime MV', 'SwingTimeA': 'SwingTime SA',}, inplace=True)\n",
        "dataset_train = data[data['Subject'].isin(['C16','C17','C19','C20','C21','C22','C23','C25','C31','C33','C34','C35','C36',\n",
        "                                           'C37','C39','C40','C41', 'C50', 'C57'\n",
        "                                           'P445','P527','P436','P440','P513','P507','P432','P441','P488','P433','P466'\n",
        "                                           ,'P484','P483','P482','P469','P462','P444','P460','P487','P528'\n",
        "                                           ])]\n",
        "\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyHNWVvHULOM"
      },
      "outputs": [],
      "source": [
        " dataset_train = dataset_train.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))\n",
        " dataset_test = dataset_test.groupby(\"Subject\").transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        " dataset_train = shuffle(dataset_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "forhF14DMrlb",
        "outputId": "151846e3-dec1-475e-dd66-72e9f6bea5b0"
      },
      "outputs": [],
      "source": [
        "X_train = dataset_train.drop(['PAD'],1)\n",
        "X_test = dataset_test.drop(['PAD'],1)\n",
        "y_train = dataset_train[['PAD']]\n",
        "y_test = dataset_test[['PAD']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFzqyc4yM6Qk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Create scaler objects\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the training data using each scaler\n",
        "X_train_standard = standard_scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using each scaler (do NOT fit again!)\n",
        "X_test_standard = standard_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OESSyjIxzdYQ",
        "outputId": "233ea262-17d0-4b99-8fe6-4f66e0a70b73"
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, tpe, hp\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define search space for hyperparameters\n",
        "search_space = {\n",
        "    'num_hidden_layers': hp.choice('num_hidden_layers', [1, 2, 3]),\n",
        "    'num_hidden_units': hp.choice('num_hidden_units', [32, 64, 128]),\n",
        "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5),\n",
        "    'batch_size': hp.choice('batch_size', [16, 32, 64]),\n",
        "    'activation': hp.choice('activation', ['relu', 'tanh', 'sigmoid']),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -6, -2),\n",
        "    'optimizer': hp.choice('optimizer', ['Adam', 'RMSprop', 'SGD']),\n",
        "    'num_epochs': hp.choice('num_epochs', [10, 20, 30])\n",
        "}\n",
        "\n",
        "# Define function to create Keras model\n",
        "def create_model(params):\n",
        "    num_hidden_layers = params['num_hidden_layers']\n",
        "    num_hidden_units = params['num_hidden_units']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "    activation = params['activation']\n",
        "    learning_rate = params['learning_rate']\n",
        "    optimizer = params['optimizer']\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_hidden_units, activation=activation, input_dim=X_train_standard.shape[1]))\n",
        "    for i in range(num_hidden_layers):\n",
        "        model.add(Dense(num_hidden_units, activation=activation))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    if optimizer == 'Adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'RMSprop':\n",
        "        opt = RMSprop(learning_rate=learning_rate)\n",
        "    elif optimizer == 'SGD':\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create Keras classifier object\n",
        "def keras_wrapper(params):\n",
        "    return KerasClassifier(build_fn=create_model, verbose=0, epochs=params['num_epochs'], batch_size=params['batch_size'])\n",
        "\n",
        "# Define objective function for hyperparameter tuning with 5-fold cross-validation\n",
        "def objective(params):\n",
        "    # Set parameters for Keras model and compile\n",
        "    model = create_model(params)\n",
        "\n",
        "    # Evaluate model with 5-fold cross-validation\n",
        "    scores = cross_val_score(keras_wrapper(params), X_train_standard, y_train, cv=5, scoring='accuracy')\n",
        "    mean_score = scores.mean()\n",
        "\n",
        "    return {'loss': -mean_score, 'status': 'ok'}\n",
        "\n",
        "# Perform hyperparameter tuning using Tree-structured Parzen Estimator (TPE) algorithm\n",
        "best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=50)\n",
        "\n",
        "print(best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c4oQWRPgMa_l",
        "outputId": "697a2473-45b0-4952-a0d6-d08ee7e1a27a"
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, tpe, hp\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam, RMSprop, SGD  # Add import statement for RMSprop\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define search space for hyperparameters\n",
        "search_space = {\n",
        "    'num_hidden_layers': hp.choice('num_hidden_layers', [1, 2, 3]),\n",
        "    'num_hidden_units': hp.choice('num_hidden_units', [32, 64, 128]),\n",
        "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5),\n",
        "    'batch_size': hp.choice('batch_size', [16, 32, 64]),\n",
        "    'activation': hp.choice('activation', ['relu', 'tanh', 'sigmoid']),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -6, -2),\n",
        "    'optimizer': hp.choice('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
        "}\n",
        "\n",
        "# Define function to create Keras model\n",
        "def create_model(params):\n",
        "  print(params)\n",
        "  num_hidden_layers = params['num_hidden_layers']\n",
        "  num_hidden_units = params['num_hidden_units']\n",
        "  dropout_rate = params['dropout_rate']\n",
        "  activation = params['activation']\n",
        "  learning_rate = params['learning_rate']\n",
        "  optimizer = params['optimizer']\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_units, activation=activation, input_dim=X_train_standard.shape[1]))\n",
        "  for i in range(num_hidden_layers):\n",
        "      model.add(Dense(num_hidden_units, activation=activation))\n",
        "      model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "  if optimizer == 'Adam':\n",
        "      opt = Adam(learning_rate=learning_rate)\n",
        "  elif optimizer == 'RMSprop':\n",
        "      opt = RMSprop(learning_rate=learning_rate)\n",
        "  elif optimizer == 'SGD':\n",
        "      opt = SGD(learning_rate=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create Keras classifier object\n",
        "classifier = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define objective function for hyperparameter tuning with 5-fold cross-validation\n",
        "def objective(params):\n",
        "    # Set parameters for cross-validation\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    # Set parameters for Keras model and compile\n",
        "    model = create_model(params)\n",
        "\n",
        "    # Evaluate model with 5-fold cross-validation\n",
        "    scores = cross_val_score(classifier, X_train_standard, y_train, cv=5, scoring='accuracy', fit_params={'batch_size': batch_size})\n",
        "    mean_score = scores.mean()\n",
        "\n",
        "    return {'loss': -mean_score, 'status': 'ok'}\n",
        "\n",
        "# Perform hyperparameter tuning using Tree-structured Parzen Estimator (TPE) algorithm\n",
        "best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=50)\n",
        "\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lCD1zd98uQg"
      },
      "outputs": [],
      "source": [
        "def create_model(layers, activation):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i, nodes in enumerate(layers):\n",
        "        if i == 0:\n",
        "            model.add(Dense(nodes, input_dim = X_train.shape[1]))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(0.3))\n",
        "        else:\n",
        "            model.add(Dense(nodes))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer ='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utc_CYBS_uCf"
      },
      "outputs": [],
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, BatchNormalization\n",
        "from keras.layers import LeakyReLU, PReLU, ELU\n",
        "from keras.layers import Dropout\n",
        "from keras.activations import relu, sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQsqbAkh8vud",
        "outputId": "2f47fedb-1ec7-4bf5-d7a0-2f5f80f6cbe2"
      },
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn = create_model, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4TNAKB__wGL"
      },
      "outputs": [],
      "source": [
        "# layers = [[20], [40,20], [45,30,15]]\n",
        "# In case your have runtime error, you may need to change the list of lists that specify the layers to a list of tuples\n",
        "# RuntimeError: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb8700b6f90>, as the constructor either does not set or modifies parameter layers\n",
        "# https://stackoverflow.com/questions/59818584/cannot-clone-object-keras-wrappers\n",
        "\n",
        "layers = [(20,), (5,5,5,5), (10,10,10,10)]\n",
        "\n",
        "# it indicates that we need a layers as 1 hidden layer with 20 neurons.\n",
        "# [40,20] will indicates 2 hidden layer, with 40 neurns at first layer, and 20 neurons on 2nd hidden layer\n",
        "# and so on\n",
        "\n",
        "# Dont forget to add (,) in (20,) otherwise it will throw an error like : TypeError: 'int' object is not iterable This is because single tuple without comma(,) is treated as int."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FitW0QkS_2y4"
      },
      "outputs": [],
      "source": [
        "activations = ['sigmoid', 'relu', 'tanh']\n",
        "\n",
        "param_grid =dict(layers = layers, activation = activations, batch_size = [128, 256], epochs = [30])\n",
        "\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2syXi0Wk_-R2"
      },
      "outputs": [],
      "source": [
        "grid_result = grid.fit(x_train_sc, y_train_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmHWRPaP82Ji",
        "outputId": "b20f36e9-b8f4-4db0-c216-fd08ea5ae3a4"
      },
      "outputs": [],
      "source": [
        "grid_result.best_score_, grid_result.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNajRiEJA7Jj",
        "outputId": "6334a680-d512-4be6-97c3-f8f9deb286ff"
      },
      "outputs": [],
      "source": [
        "y_pred = grid.predict(x_test_sc)\n",
        "y_pred = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "IlAQWLygA_UD",
        "outputId": "3ed59887-1880-4700-faaa-caae12c430d0"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('gait3.csv')\n",
        "dataset_test = data[data['Subject'].isin(['C11','C38','C43','C48','C49','C53','P459','P458','P457','P450',\n",
        "                                          'P473','P477','P503'])]\n",
        "sub = pd.DataFrame(dataset_test['Subject'])\n",
        "sub['actual'] = y_test_sc\n",
        "sub['prediction'] = y_pred\n",
        "f = sub.groupby(\"Subject\", as_index = False).mean()\n",
        "\n",
        "print(classification_report(f.actual, f.prediction))\n",
        "print(\"Precision:{}\".format(precision_score(f.prediction,f.actual)))\n",
        "print(\"Recall:{}\".format(recall_score(f.prediction,f.actual)))\n",
        "print(\"F1 Score:{}\".format((f1_score(f.prediction,f.actual))))\n",
        "\n",
        "cm = confusion_matrix(f.actual, f.prediction)\n",
        "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "plt.title(\"Accuracy: %.2f%%\" % (accuracy_score(f.actual, f.prediction)*100))\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "wl6eGlaQGNJI",
        "outputId": "61aa4ad9-1315-4c60-c1f0-3ca2f58b3805"
      },
      "outputs": [],
      "source": [
        "f = f[['Subject', 'prediction', 'actual']]\n",
        "f.columns = ['Subject', 'Prediction', 'Actual']\n",
        "f"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
